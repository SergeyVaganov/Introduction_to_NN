{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca2d902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e567bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# установка параметров нейросети\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "data_augmentation = True\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c3ccc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n"
     ]
    }
   ],
   "source": [
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "358d2ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "606e747c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d944848430>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88e81e9",
   "metadata": {},
   "source": [
    "## BaseLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a39d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9117be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17e2e514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 101s 253ms/step - loss: 2.0113 - accuracy: 0.2611 - val_loss: 1.8043 - val_accuracy: 0.3611\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 99s 254ms/step - loss: 1.7532 - accuracy: 0.3631 - val_loss: 1.5976 - val_accuracy: 0.4270\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 100s 256ms/step - loss: 1.6508 - accuracy: 0.4004 - val_loss: 1.4945 - val_accuracy: 0.4549\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 98s 251ms/step - loss: 1.5764 - accuracy: 0.4272 - val_loss: 1.4132 - val_accuracy: 0.4926\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 100s 256ms/step - loss: 1.5170 - accuracy: 0.4506 - val_loss: 1.4194 - val_accuracy: 0.4932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d943377b20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# запуск data augmentation через fit_generator\n",
    "model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17086e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 14ms/step - loss: 1.4194 - accuracy: 0.4932\n",
      "Test loss: 1.419377088546753\n",
      "Test accuracy: 0.49320000410079956\n"
     ]
    }
   ],
   "source": [
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e1f845",
   "metadata": {},
   "source": [
    "## Улучшенная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e0a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='selu', input_shape=x_train.shape[1:]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='selu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "# shape (16,16)\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='selu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='selu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "# shape (8,8)\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='selu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='selu', input_shape=x_train.shape[1:]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "# shape (4,4)\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='selu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='selu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "# shape (2,2)\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='selu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='selu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "# shape (1,1)\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('selu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('selu'))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59fe579",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=0.5)\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c533670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_decayed_fn = keras.optimizers.schedules.CosineDecay(initial_learning_rate=0.001, decay_steps=1000)\n",
    "opt = keras.optimizers.Adamax(learning_rate=lr_decayed_fn)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebe4909a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 618s 2s/step - loss: 1.6937 - accuracy: 0.4197 - val_loss: 2.7589 - val_accuracy: 0.2581\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 631s 2s/step - loss: 1.2202 - accuracy: 0.5619 - val_loss: 1.2019 - val_accuracy: 0.5885\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 633s 2s/step - loss: 1.0699 - accuracy: 0.6162 - val_loss: 1.0618 - val_accuracy: 0.6242\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 634s 2s/step - loss: 1.0586 - accuracy: 0.6207 - val_loss: 1.0616 - val_accuracy: 0.6249\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 628s 2s/step - loss: 1.0594 - accuracy: 0.6221 - val_loss: 1.0655 - val_accuracy: 0.6234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d903b52cd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "021e4221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 17s 53ms/step - loss: 1.0655 - accuracy: 0.6234\n",
      "Test loss: 1.065549612045288\n",
      "Test accuracy: 0.6233999729156494\n"
     ]
    }
   ],
   "source": [
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827205fb",
   "metadata": {},
   "source": [
    "Выводы: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63dfefc",
   "metadata": {},
   "source": [
    "К увеличению точности привело:\n",
    "- Изменение Dropout, в базовой модели этот параметр был завышен. \n",
    "- Изменение скорости обучения через планировщик так же позволяет более точно обучить модель. \n",
    "- Увеличение числа слоёв  даёт возможность сети обучать большее числе паттернов, \n",
    "- Увеличение receptive field позволяет анализировать большие объекты. В нашем датасете имеются объекты полностью занимающие картинку я постарался сделать receptive field максимальным."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287d7384",
   "metadata": {},
   "source": [
    "### Вопрос 2\n",
    "\n",
    "Опишите в анализе, какие изменения необходимо было бы внести в получившуюся нейронную сеть, если бы ей нужно было работать не с cifar10, а с MNIST, CIFAR100 и IMAGENET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec8fb0c",
   "metadata": {},
   "source": [
    "CIFAR100 - полностью аналогичен cifar10, отличается количеством размеченных классов. <br>\n",
    "Таким образом для обучения полученной нами сети на CIFAR100, необходимо поменять число классов в выходном слое  <br>\n",
    ">__num_classes = 100<br>\n",
    "model.add(Dense(num_classes))<br>\n",
    "model.add(Activation('softmax'))__<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4aab7",
   "metadata": {},
   "source": [
    "С обучением моей сети на MNIST дела немного посложнее<br> \n",
    "1. MNIST имеет размерность выборки <br> x_train shape: (60000, 28, 28) поэтому сначала необходимо добавить еще одну ось, чтобы не \"ругался\" ImageDataGenerator\n",
    "\n",
    ">__x_train = x_train.reshape(60000,28,28,1)__\n",
    "\n",
    "\n",
    "\n",
    "2. Размер изображения в датасете 28*28, чтобы модель смогла работать необходимо удалить последний блок с 512 фильтрами.  \n",
    "\n",
    ">__model.add(Conv2D(512, (3, 3), padding='same', activation='selu'))<br>\n",
    " model.add(keras.layers.BatchNormalization())<br>\n",
    " model.add(Conv2D(512, (3, 3), padding='same', activation='selu'))<br>\n",
    " model.add(keras.layers.BatchNormalization())<br>\n",
    " model.add(MaxPooling2D(pool_size=(2, 2)))<br>\n",
    " model.add(Dropout(0.1))__<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8edcda",
   "metadata": {},
   "source": [
    "IMAGENET имеет набор изображений различного разрешения, и всегда больше 32*32, таким образом можно воспользоваться например функцией  \n",
    ">__datagen.flow_from_directory(... target_size=(32, 32) ...)__\n",
    "\n",
    "flow_from_directory - Принимает путь к каталогу и генерирует пакеты расширенных данных.\n",
    "target_size - кортеж целых (height, width)чисел, по умолчанию (256,256). Размеры, до которых будут изменены все найденные изображения.\n",
    "После чего сеть будет обучаться на предоставленных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53beb7ba",
   "metadata": {},
   "source": [
    "В последнем случае имеет смысл всё-таки воспользоваться уже предобученной сетью на датасете IMAGENET"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

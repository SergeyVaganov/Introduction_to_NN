{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b647b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "571da0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f961fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       178 non-null    float64\n",
      " 1   1       178 non-null    float64\n",
      " 2   2       178 non-null    float64\n",
      " 3   3       178 non-null    float64\n",
      " 4   4       178 non-null    float64\n",
      " 5   5       178 non-null    float64\n",
      " 6   6       178 non-null    float64\n",
      " 7   7       178 non-null    float64\n",
      " 8   8       178 non-null    float64\n",
      " 9   9       178 non-null    float64\n",
      " 10  10      178 non-null    float64\n",
      " 11  11      178 non-null    float64\n",
      " 12  12      178 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 18.2 KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data.data)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d941bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  178.000000  178.000000  178.000000  178.000000  178.000000  178.000000   \n",
       "mean    13.000618    2.336348    2.366517   19.494944   99.741573    2.295112   \n",
       "std      0.811827    1.117146    0.274344    3.339564   14.282484    0.625851   \n",
       "min     11.030000    0.740000    1.360000   10.600000   70.000000    0.980000   \n",
       "25%     12.362500    1.602500    2.210000   17.200000   88.000000    1.742500   \n",
       "50%     13.050000    1.865000    2.360000   19.500000   98.000000    2.355000   \n",
       "75%     13.677500    3.082500    2.557500   21.500000  107.000000    2.800000   \n",
       "max     14.830000    5.800000    3.230000   30.000000  162.000000    3.880000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  178.000000  178.000000  178.000000  178.000000  178.000000  178.000000   \n",
       "mean     2.029270    0.361854    1.590899    5.058090    0.957449    2.611685   \n",
       "std      0.998859    0.124453    0.572359    2.318286    0.228572    0.709990   \n",
       "min      0.340000    0.130000    0.410000    1.280000    0.480000    1.270000   \n",
       "25%      1.205000    0.270000    1.250000    3.220000    0.782500    1.937500   \n",
       "50%      2.135000    0.340000    1.555000    4.690000    0.965000    2.780000   \n",
       "75%      2.875000    0.437500    1.950000    6.200000    1.120000    3.170000   \n",
       "max      5.080000    0.660000    3.580000   13.000000    1.710000    4.000000   \n",
       "\n",
       "                12  \n",
       "count   178.000000  \n",
       "mean    746.893258  \n",
       "std     314.907474  \n",
       "min     278.000000  \n",
       "25%     500.500000  \n",
       "50%     673.500000  \n",
       "75%     985.000000  \n",
       "max    1680.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a6dfff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class_0', 'class_1', 'class_2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098fb986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f4537ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6cac88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 1, 2, 0, 0, 0, 2, 0, 0, 1, 2, 1, 0, 2, 1, 0, 2, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 2, 1, 1, 1, 0, 1, 1, 1, 2, 2, 0, 1, 2, 2, 1, 1,\n",
       "       0, 1, 2, 2, 1, 2, 1, 1, 1, 0, 0, 2, 0, 2, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 2, 1, 1, 1, 2, 2, 1, 0, 0, 1, 2, 2, 0, 1, 2, 2, 2, 2, 1, 0,\n",
       "       1, 0, 2, 0, 0, 1, 0, 0, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 1, 1, 1, 1,\n",
       "       1, 1, 2, 0, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef6d6b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9089fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ker_init = keras.initializers.RandomNormal(mean=0, stddev=0.1, seed=42)\n",
    "# ker_init = keras.initializers.RandomUniform(minval=-0.5, maxval=0.5, seed = 42)\n",
    "bias_init = keras.initializers.RandomNormal(mean=0, stddev=0.1, seed=42)\n",
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape = [13]),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dense(254, activation=\"relu\", kernel_initializer=ker_init, bias_initializer=bias_init),\n",
    "keras.layers.Dropout(rate=0.4, seed=42),\n",
    "keras.layers.Dense(254, activation=\"relu\", kernel_initializer=ker_init, bias_initializer=bias_init),\n",
    "keras.layers.BatchNormalization(),    \n",
    "keras.layers.Dense(254, activation=\"relu\", kernel_initializer=ker_init, bias_initializer=bias_init),\n",
    "keras.layers.Dense(3, activation=\"softmax\")  \n",
    "])\n",
    "\n",
    "boundaries = [2000, 3000]\n",
    "values = [0.01, 0.005, 0.001]\n",
    "lr_schedule = keras.optimizers.schedules.PiecewiseConstantDecay(boundaries, values)\n",
    "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a11a6933",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 [==============================] - 1s 4ms/step - loss: 0.7520 - accuracy: 0.7143\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.8908\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.9496\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1001 - accuracy: 0.9916\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1667 - accuracy: 0.9664\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9748\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.9664\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1095 - accuracy: 0.9916\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9916\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.9328\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1370 - accuracy: 0.9748\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1273 - accuracy: 0.9832\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1257 - accuracy: 0.9664\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1505 - accuracy: 0.9748\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0762 - accuracy: 0.9832\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9832\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9832\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9832\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0892 - accuracy: 0.9664\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0206 - accuracy: 0.9916\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0802 - accuracy: 0.9748\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9916\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9916\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.9916\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9916\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9916\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9916\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 9.3531e-04 - accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9832\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.5294e-04 - accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.9748\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 0.9832\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0901 - accuracy: 0.9748\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9832\n",
      "Epoch 40/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1321 - accuracy: 0.9748\n",
      "Epoch 41/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.9664\n",
      "Epoch 42/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9916\n",
      "Epoch 43/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9832\n",
      "Epoch 44/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9916\n",
      "Epoch 46/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.9916\n",
      "Epoch 47/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.9916\n",
      "Epoch 48/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1123 - accuracy: 0.9580\n",
      "Epoch 50/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9916\n",
      "Epoch 51/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 0.9916\n",
      "Epoch 53/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.9916\n",
      "Epoch 54/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1651 - accuracy: 0.9664\n",
      "Epoch 55/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9832\n",
      "Epoch 56/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9916\n",
      "Epoch 58/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9832\n",
      "Epoch 60/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1587 - accuracy: 0.9580\n",
      "Epoch 61/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.7725e-04 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.4396e-04 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9916\n",
      "Epoch 72/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.5402e-05 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.9748\n",
      "Epoch 74/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.9916\n",
      "Epoch 75/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9916\n",
      "Epoch 76/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.9916\n",
      "Epoch 77/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9916\n",
      "Epoch 78/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0931 - accuracy: 0.9580\n",
      "Epoch 79/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9832\n",
      "Epoch 80/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9748\n",
      "Epoch 81/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 8.1635e-04 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.9832\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9916\n",
      "Epoch 85/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9832\n",
      "Epoch 88/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6419e-05 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6524e-04 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9916\n",
      "Epoch 92/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.4369e-05 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9916\n",
      "Epoch 96/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9916\n",
      "Epoch 98/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1185 - accuracy: 0.9916\n",
      "Epoch 99/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.0725e-04 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9832\n",
      "Epoch 102/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0987 - accuracy: 0.9748\n",
      "Epoch 104/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1906 - accuracy: 0.9748\n",
      "Epoch 105/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 8.9560e-04 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1193 - accuracy: 0.9664\n",
      "Epoch 107/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1111 - accuracy: 0.9748\n",
      "Epoch 108/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5826 - accuracy: 0.8992\n",
      "Epoch 109/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9328\n",
      "Epoch 110/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0886 - accuracy: 0.9748\n",
      "Epoch 111/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2271 - accuracy: 0.9580\n",
      "Epoch 112/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9916\n",
      "Epoch 113/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9748\n",
      "Epoch 117/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9832\n",
      "Epoch 120/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9832\n",
      "Epoch 121/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.9916\n",
      "Epoch 122/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0738 - accuracy: 0.9832\n",
      "Epoch 123/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9664\n",
      "Epoch 124/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9916\n",
      "Epoch 125/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.0995e-04 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9916\n",
      "Epoch 127/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 8.0333e-04 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.2534e-04 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.1234e-04 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9916\n",
      "Epoch 132/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.6975e-05 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 0.9916\n",
      "Epoch 135/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1219 - accuracy: 0.9580\n",
      "Epoch 137/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9832\n",
      "Epoch 139/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1649 - accuracy: 0.9916\n",
      "Epoch 140/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9916\n",
      "Epoch 141/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9916\n",
      "Epoch 144/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.2894e-04 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9832\n",
      "Epoch 146/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 0.9916\n",
      "Epoch 148/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 8.5620e-05 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9832\n",
      "Epoch 150/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e8a4db3eb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, \n",
    "          to_categorical(y_train), \n",
    "          epochs=150, \n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "973d4396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step - loss: 0.0011 - accuracy: 1.0000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.001084073563106358, 1.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(\n",
    "  X_test,\n",
    "  to_categorical(y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9290c0",
   "metadata": {},
   "source": [
    "## Вариант с использованием стандартной библиотеки ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "230a45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b9c0a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d50069bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(data.data, data.target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45d22f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X1_train = scaler.fit_transform(X1_train)\n",
    "X1_test = scaler.transform(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef132189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=30, random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 30, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90185885",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17785e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y1_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24f712d",
   "metadata": {},
   "source": [
    "## Выводы:\n",
    "    \n",
    "    Довольно простой датасет, и на мой взгляд, модель классического ML справилась с решением этой задачи проще и быстрее. \n",
    "    Можно сделать вывод что сети глубокого обучения не всегда являются лучшим вариантом решения поставленных задач. Большое число обучаемых параметров, сложность определения оптимальных значений являются минусами нейронной сети, поэтому имеет смысл при анализе данных проверять а, не может ли с этой задачей справиться классическая модель. \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5be72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
